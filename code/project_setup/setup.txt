------ VERSION WITH GIT ----- 10/02/2026

# Ecommerce Analytics ELT (Azure Data Lake + Snowflake + dbt)
# FULL CLEAN SETUP (Windows / PowerShell)
#
# What this script does:
# 1) Uses your existing project root folder (Documents)
# 2) Normalizes folder structure: data/, code/, notes/
# 3) Recreates a local Python venv in the project root: .venv/
# 4) Installs dbt-snowflake inside the venv
# 5) Initializes Git at the project root + creates a solid .gitignore
# 6) Creates a dbt project under: code\dbt\analytics_dbt
# 7) Opens profiles.yml for Snowflake credentials (outside repo)
# 8) Runs dbt debug to validate connection
# ==========================================================

# ----------------------------
# 0) Create project folder
# ----------------------------
mkdir C:\Users\User\Documents\ecommerce-analytics-elt -Force
cd C:\Users\User\Documents\ecommerce-analytics-elt

# ----------------------------
# 1) Create folders 

mkdir ".\data" -Force
mkdir ".\code" -Force
mkdir ".\notes" -Force
mkdir ".\code\project_setup" -Force
mkdir ".\code\dbt" -Force
mkdir ".\code\ingestion" -Force

# ----------------------------
# 2) Create envelope (delete any old venv + recreate)
# Creates: C:\Users\User\Documents\ecommerce-analytics-elt\.venv\
# ----------------------------
Remove-Item -Recurse -Force ".\.venv" -ErrorAction SilentlyContinue
python -m venv .venv

# Activate venv (after this, pip installs go into .venv)
.\.venv\Scripts\Activate.ps1

# Upgrade pip inside the venv (avoids dependency issues)
python -m pip install --upgrade pip

# Install dbt adapter for Snowflake (dbt core comes with it)
pip install dbt-snowflake

# Verify dbt is runnable and which versions you have
dbt --version

# ----------------------------
# 3) Initialize Git at the project root (best practice for a full portfolio project)
# Repo will include: data/, notes/, code/, README.md
# ----------------------------
git init

# Create/overwrite a solid .gitignore at ROOT (important!)
# - .venv is local
# - dbt artifacts (target/logs/dbt_packages) are generated
# - editor/OS junk ignored
@"
# --- Python virtual environment (local only)
.venv/

# --- dbt generated artifacts (ignore anywhere in the repo)
**/target/
**/dbt_packages/
**/logs/

# --- OS / editor
.vscode/
.DS_Store
Thumbs.db

# --- Python caches
__pycache__/
*.pyc

# --- Safety: if profiles.yml ever ends up in repo by mistake, ignore it
profiles.yml
"@ | Set-Content -Path ".\.gitignore" -Encoding UTF8

# Create a minimal README if it doesn't exist
if (!(Test-Path ".\README.md")) {
@"
# Ecommerce Analytics – Warehousing & ELT (Azure Data Lake + Snowflake + dbt)

Portfolio end-to-end ELT project:
- Landing: Azure Data Lake Storage (ADLS)
- Warehouse: Snowflake
- Transformations: dbt (staging → marts)
"@ | Set-Content -Path ".\README.md" -Encoding UTF8
}

# Setting username 
git config --global user.name "Federico Garland"
git config --global user.email "federicogarlands@gmail.com" 

# Adding and commiting changes (to local repository)
git add .
git commit -m "Initialize project structure (repo root, venv, ignore rules)"

# Pushing to GitHub 
git branch -M main
git remote add origin https://github.com/FedericoGarland/ecommerce-analytics-elt
git push -u origin main


# ----------------------------
# 4) Create dbt project inside code\dbt\
# Creates folder: ...\ecommerce-analytics-elt\code\dbt\analytics_dbt\
# ----------------------------
cd ".\code\dbt"

dbt init ecommerce_dbt
cd ".\ecommerce_dbt"

# Commit dbt scaffold to the ROOT git repo
cd "..\..\.."   # back to project root
git add .
git commit -m "Add dbt project scaffold under code/dbt/ecommerce_dbt"
git push

# ----------------------------
# 5) Configure Snowflake connection (profiles.yml OUTSIDE repo)
# dbt reads from: C:\Users\User\.dbt\profiles.yml
# ----------------------------
cd ".\code\dbt\ecommerce_dbt"

# Show where dbt expects the config directory:
dbt debug --config-dir

# Open profiles.yml to edit manually 
notepad $env:USERPROFILE\.dbt\profiles.yml

# ----------------------------
# 6) Validate connection (after you save profiles.yml)
# ----------------------------
dbt debug


# Run dbt to create default models 
dbt run

# Commit 
cd "..\..\.."
git add .
git commit -m "dbt connected to Snowflake and first models created"






# APUNTES ------------------------------------------------- 
# Estructura PowerShell: comando accion -opcion valor
# valor = argumento
# la diferencia entre un guion y dos guiones es solo que uno es version corta y otra version larga
# Los guiones (que son opciones, es decir modificadores para comandos) pueden significar cosas distintas en distintos programas (dbt, git, python) aunque ejecutes todo dentro de PowerShell
# En " python -m pip" es Python quien interpreta el -m, no PowerShell 
# Los guiones sirven para modificar el comportamiento, activar/desactivar cosas y pasar parámetros. 
# dbt run --full-refresh solo activa un modo y no lleva valor. 
# git commit -m "message" si es una opcion que requiere valor. 
# python -m pip modifica el comportamiento haciendo que Python ejecute lo siguiente como programa 
# el significado de las opciones depende del comando que las precede. Por ejemplo, en git commit -m, el -m significa message. Mientras tanto, en git branch -m, el -m significa rename. 



# EJEMPLO DE ACCIONES 
git commit
dbt run
pip install
python script.py

# EJEMPLO DE ACCIONES CON OPCIONES (MODIFICADORES)
git commit -m
dbt run --select
pip install --upgrade
python -m

